tr1<-unique(train$theme_name)
te1[!(te1 %in% tr1)]
tr1[!(te1 %in% tr1)]
dim(test)
test <- test[!test$theme_name==c("Power Functions","Dinosaurs"),]
train <- train[!train$theme_name==c("Power Functions","Dinosaurs"),]
#Remove new levels in sub_theme.x between test and train
se1 <-unique(test$sub_theme.x)
sr1<-unique(train$sub_theme.x)
se1[!(se1 %in% sr1)]
sr1[!(se1 %in% sr1)]
test <- test[!test$sub_theme.x==c("Master Building Academy","Fusion"),]
train <- train[!train$sub_theme.x==c("Master Building Academy","Fusion"),]
dim(test)
dim(train)
#Remove new levels in partcat_name between test and train
pe1 <-unique(test$partcat_name)
pr1<-unique(train$partcat_name)
pe1[!(pe1 %in% pr1)]
pr1[!(pe1 %in% pr1)]
dim(test)
dim(train)
#Remove new levels in year between test and train
ye1 <-unique(test$year)
yr1<-unique(train$year)
ye1[!(ye1 %in% yr1)]
yr1[!(ye1 %in% yr1)]
test <- test[!test$year==c("1964","1966"),]
train <- train[!train$year==c("1964","1966"),]
dim(test)
dim(train)
###### 3. Variable Selection #############
library(leaps)
#Data Exploration and Variable Selection
plot(USPrice~year+is_trans+version+theme_name+sub_theme.x+partcat_name+is_spare+color_name, data = train)
#Year seems to have a high related positive relationship
#version - related 1, or 2, positive
###### 4. Fit Linear Regression Models #############
#1. Build linear model using year variable
# s.null <- lm(USPrice~1, data=train)
# s.full <- lm(USPrice~ is_trans + partcat_name + theme_name + sub_theme.x + version + year,
#              data = train)
#
# Stepwise selection
# step(s.null, scope=list(lower=s.null, upper=s.full), direction="both")
## Variable Selection:
## part_num, part_name, set_num, set_num, and num_part have thousands levels, not good for modeling
## color_name, rgb, is_spares are not related much with USPrice.
## Therefore,
## 6 Variables: year, version, in_trans, theme_name, sub_theme.x, partcat_nam,
## which have high association with USPrice, are selected as predictors for modeling.
###### 4. Cross Validation: K=5 #############
library(MASS)
set.seed(123)
#2. Built linear regression model using the following 6 variables based on step wise selection
#Check the full model
price.lm <- lm(USPrice~ is_trans + partcat_name + theme_name + sub_theme.x + version + year, data = train,x = TRUE, y = TRUE)
summary(price.lm)
summary(price.lm)
qqnorm(rstudent(price.lm))
qqline(rstudent(price.lm))
out <- boxcox(price.lm)
range(out$x[out$y > max(out$y)-qchisq(0.95,1)/2])
summary(train0$USPrice)
summary(train$USPrice)
summary(log10(train$USPrice))
train$USPrice_trans <- log(train0$USPrice)
train$USPrice_trans <- log(train$USPrice)
price_trans.lm <- lm(USPrice_trans~ is_trans + partcat_name + theme_name + sub_theme.x + version + year, data = train)
qqnorm(rstudent(price_trans.lm))
qqline(rstudent(price_trans.lm))
qqline(rstudent(price_trans.lm))
qqnorm(rstudent(price.lm))
qqline(rstudent(price.lm))
ti <- rstudent(price0_trans.lm)
yhat <- fitted(price0_trans.lm)
plot(yhat,ti)
abline(h=0)
ti <- rstudent(price_trans.lm)
yhat <- fitted(price_trans.lm)
plot(yhat,ti)
abline(h=0)
price_trans.lm <- lm(USPrice_trans~ is_trans + partcat_name + theme_name + sub_theme.x + version + year, data = train, x =T, y =T)
cv.trans.error = cv.lm(price.lm, K=5, max_cores = 4)
library(MASS)
cv.trans.error = cv.lm(price.lm, K=5, max_cores = 4)
library(lmvar)
cv.trans.error = cv.lm(price_trans.lm, K=5, max_cores = 4)
cv.error
cv.trans.error
pred <- predict(price_trans.lm, newdata = test)
test <- test[!test$theme_name=="Power Functions",]
test <- test[!test$theme_name=="Power Functions",]
pred <- predict(price_trans.lm, newdata = test)
test <- test[!test$theme_name=="Dinasours",]
test <- test[!test$sub_theme.x=="Master Building Academy",]
test <- test[!test$sub_theme.x=="Fusion",]
test <- test[!test$sub_theme.x == "The Lord of the Rings",]
pred <- predict(price_trans.lm, newdata = test)
test <- test[!test$sub_theme.x == "Marvel Super Heros",]
pred <- predict(price_trans.lm, newdata = test)
levels(test$sub_theme.x)
test$sub_theme.x == "Marvel Super Heroes"
which(test$sub_theme.x == "Marvel Super Heroes" ,])
which(test$sub_theme.x == "Marvel Super Heroes")
test <- test[!test$sub_theme.x == "Marvel Super Heroes" ,]
test$sub_theme.x == "Marvel Super Heroes"
which(test$sub_theme.x == "Marvel Super Heroes")
pred <- predict(price_trans.lm, newdata = test)
length(pred)
mse <- mean(test$USPrice - pred)^2
mse
pred <- predict(price.lm, newdata = test)
length(pred)
mse <- mean(test$USPrice - pred)^2
mse
summary(price.lm)
summary(price_trans.lm)
trans_pred <- predict(price_trans.lm, newdata = test)
length(pred)
mse <- mean(log(test$USPrice) - pred)^2
mse
log(test$USPrice)
log(test$USPrice)
pred
mse <- mean(log(test$USPrice) - trans_pred)^2
mse
pred <- predict(price.lm, newdata = test)
length(pred)
mse <- mean(test$USPrice - pred)^2
mse
pred <- predict(price.lm, newdata = test)
length(pred)
mse <- mean(test$USPrice - pred)^2
mse
test$USPrice - pred
mse <- mean(sum(test$USPrice - pred)^2)
mse
sum(test$USPrice - pred)
View(master_df_final)
582/600*.25
582/600*25
70/100*30
790/800*25
95/100*25
24.25+21+24.68+23.75
790/800*20
24.25+21+19.75+23.75
0.25/3
0.25/3 +2/3
2.25/3
2.25/3 +0.25/3
1/12/29/80
2/9
1/9
0.25/3.85
0.8/5.8
0.4/.29
0.4/2.9
4/9
1/5.8
(1/15)/(29/80)
140/11
100/11
-15 +(100/11/4)
(1/12+1/15+1/3)*3/4
1/12+1/15+1/3
(1/12+1/15+1/3)*0.75
29/80
1/12
0.25/3
1/12 + 1/15 + 1/3
(1/12 + 1/15 + 1/3)*0.75
29/80
1/12/(29/80)
(1/15)/(29/80)
0.25/9/(.25/9 +0.8/9 + 4/9)
library(plyr)
library(caret)
library(pROC)
library(tidyverse)
library(plotROC)
library(MASS)
library(car)
library(glmnet)
#Parallelization
library(parallel)
library(doParallel)
library(caret)
set.seed(11)
########################## Reading & Splitting Data ##############################
dir = '/Users/babraham/Google Drive/Grad_School/Cyber_Research/Anomaly-based-Intrusion-Detection-System/Code/Data Modelling/R'
all_data <- read.csv('merged_data_final.csv', header=T) #reading in the data
perform_LOO <- function(LOO_datasets, thresh, mtype="lr"){
if(mtype == "nn"){mtype = "mlpML" }
mal_data <- LOO_datasets[[1]]
family_mal_data <- LOO_datasets[[2]]
if(mtype == "lr"){
# Apply log trnasform to skewed predictors
mal_data[skewed_columns] <- sapply(mal_data[skewed_columns], function(x) log(x+1))
family_mal_data[skewed_columns] <- sapply(family_mal_data[skewed_columns], function(x) log(x+1))
# Create final model with LOO as test and all other as train
final_model <- cv.glmnet(as.matrix(mal_data[,-c(1)]),as.matrix(mal_data[,'Malicious']), alpha = 1)
final_lambda_lse <- final_model$lambda.1se
#Evaluate model on LOO test data
probs <- predict(final_model,newx = as.matrix(family_mal_data[,-c(1)]),s=final_lambda_lse,type="response")
preds <- rep(0,nrow(probs))
preds[probs>thresh] <- 1
}
else{ #use caret packet to train any other model type (rf, nb, svm,nn)
mlp_grid = NULL
preProc = c("center")
if(mtype == "mlpML"){ #if nn, need to set up params for tuneGrid. Otherwise, set mlp_grid to empty variable
num_vars = ncol(mal_data)-1
mlp_grid = expand.grid(layer1 = c(10),
layer2 = c(5),
layer3 = c(0))
preProc <- c("range")
}
#if(mtype == "nb"){
#    }
cluster <- makeCluster(detectCores())
registerDoParallel(cluster)
set.seed(234)
control <- trainControl(method="cv",
summaryFunction=twoClassSummary, classProbs=T,
savePredictions = T,allowParallel = TRUE)
#Convert response variable to factor for train and test datasets
mal_data$Malicious <- as.factor(mal_data$Malicious)
levels(mal_data$Malicious) <- c('Benign','Malicious')
family_mal_data$Malicious <- as.factor(family_mal_data$Malicious)
levels(family_mal_data$Malicious) <- c('Benign','Malicious')
#train model
model <- train(x=mal_data[,-1], y = as.factor(mal_data[,'Malicious']), method = mtype,
trControl=control,
preProcess = preProc,
metric = "ROC",
tuneLength = 4,
tuneGrid = mlp_grid)
#predict on test data and calculate accuracy
probs <- predict(model,newdata = family_mal_data[,-c(1)], type="prob")
probs <- probs$Malicious
preds <- rep(0,length(probs))
preds[probs>thresh] <- 1
preds <- as.factor(preds)
levels(preds) <- c('Benign', 'Malicious')
preds_table <- table(family_mal_data[,'Malicious'], preds)
accuracy <- (preds_table[1,1] + preds_table[2,2]) / sum(preds_table)
}
# Create confusion matrix
cnfMatrix <- confusionMatrix(preds, family_mal_data[,'Malicious'])
# Calculate AUC values
roccurve <- pROC::roc(family_mal_data[,'Malicious'] ~ as.vector(probs))#
#plot(roccurve)
auc_value <- pROC::auc(roccurve)
return(list(cnfMatrix$byClass['Balanced Accuracy'][1],cnfMatrix$byClass['Precision'],
cnfMatrix$byClass['Recall'],cnfMatrix$byClass['F1'],
auc_value))
}
setwd("C:/Users/abhij/Desktop/UVa Coursework/Capstone/Anomaly-based-Intrusion-Detection-System/Code/Data Modelling/R")
all_data <- read.csv('merged_data_final.csv', header=T) #reading in the data
all_data <- all_data[which(all_data$File != "traces_141_1.log.csv"),]
#get rid of index
all_data <- all_data[,-c(1)]
drop_cols <- c('srcIP','destIP','destPt','protocol','startTime','File','File.1','Type','Family')
########################## Log transform skewed columns ##############################
skewed_columns <- c('flowct','mean_dest_bytes','stdev_dest_bytes','mean_dest_pkts','stdev_dest_pkts','mean_duration',
'stdev_duration','mean_intvl','stdev_intvl','mean_src_pkts','stdev_src_pkts',
'A','C','D','F','H','R','S','T','a','c','d','f','h','r','t')
########################## Summary statistics by bot family ##############################
malicious_traces <- all_data[all_data$Family!='Normal',]
all_data$Family  <- factor(all_data$Family , levels = c('Bunitu', 'Conflicker', 'Dridex', 'Miuref', 'Necurs', 'Trickbot', 'Upatre', 'Zeus', 'Normal'))
summary_flowct <- malicious_traces %>% group_by(Family) %>% summarise('Median (Flowcount)'= round(median(flowct),1), 'Std dev (Flowcount)' = round(sd(flowct),1),
'Median (Mean Duration)'= round(median(mean_duration),1), 'Std dev (Mean Duration)' = round(sd(mean_duration),1),
'Median (Mean Source Packets)'= round(median(mean_src_pkts),1), 'Std dev (Mean Source Packets)' = round(sd(mean_src_pkts),1))
#View(summary_flowct)
########################## Log transform skewed columns ##############################
#all_data[skewed_columns] <- sapply(all_data[skewed_columns], function(x) log(x+1))
########################## Create LOO function ##############################
create_LOO_datasets <- function(all_data, family_nm, thresh){
drop_cols <- c('srcIP','destIP','destPt','protocol','startTime','File','File.1','Type','Family')
# Separate out normal traces from malicious traces
normal_data <- all_data[all_data['Family']=='Normal',!(colnames(all_data) %in% drop_cols)]
# Index for normal test data
normal_test_index <- sample(1:nrow(normal_data),nrow(all_data[all_data['Family']==family_nm,]),replace = FALSE )
# Create dataset with only malicious traces
all_data2 <- all_data[all_data['Family']!='Normal',]
# Remove traces of family_nm (LOO family) to create mal data
mal_data <- all_data2[all_data2['Family']!=family_nm,!(colnames(all_data2) %in% drop_cols)]
# Append train normal data to malicious data
mal_data <- rbind(mal_data, normal_data[-normal_test_index,])
# Create family mal data containing traces of LOO family
family_mal_data <- all_data2[all_data2['Family']==family_nm,!(colnames(all_data2) %in% drop_cols)]
# Append test normal data to LOO malicious data
family_mal_data <- rbind(family_mal_data, normal_data[normal_test_index,])
return(list(mal_data, family_mal_data))
}
########################## Create Logistic Regression function ##############################
logistic_regr_LOO <- function(LOO_datasets, thresh){
mal_data <- LOO_datasets[[1]]
family_mal_data <- LOO_datasets[[2]]
# Create train index for malicious dataset (all families other than LOO)
train_mal_index <- sample(1:nrow(mal_data), round(0.7*nrow(mal_data)), replace = FALSE)
# Create test and train datasets
train_data <- as.matrix(mal_data[train_mal_index,])
test_data <- as.matrix(mal_data[-train_mal_index,])
# train the model
model <- cv.glmnet(train_data[,-c(1)],train_data[,'Malicious'], alpha = 1)
lambda_1se <- model$lambda.1se
probs <- predict(model,newx = test_data[,-c(1)],s=lambda_1se,type="response")
preds <- rep(0,nrow(probs))
preds[probs>thresh] <- 1
preds_table <- table(test_data[,'Malicious'], preds)
accuracy <- (preds_table[1,1] + preds_table[2,2]) / sum(preds_table)
# Create final model with LOO as test and all other as train
final_model <- cv.glmnet(as.matrix(mal_data[,-c(1)]),as.matrix(mal_data[,'Malicious']), alpha = 1)
final_lambda_lse <- final_model$lambda.1se
probs <- predict(final_model,newx = as.matrix(family_mal_data[,-c(1)]),s=final_lambda_lse,type="response")
preds <- rep(0,nrow(probs))
preds[probs>thresh] <- 1
# Create confusion matrix
cnfMatrix <- confusionMatrix(preds, as.factor(family_mal_data[,'Malicious']))
# Calculate AUC values
roccurve <- pROC::roc(family_mal_data[,'Malicious'] ~ as.vector(probs))#
#plot(roccurve)
auc_value <- pROC::auc(roccurve)
# # Create ROC plots using ROCR package
# roc_pred <- ROCR::prediction( as.vector(probs), family_mal_data[,'Malicious'] )
# roc_perf <- ROCR::performance( roc_pred, "tpr", "fpr" )
#
# # Create ROC plots for Miuref and Bunitu
# if(family_nm=='Miuref'){
#   plot( roc_perf, col = "black", lty=3)
#   legend("topright", c(family_nm), lty=3,
#          col = "black", bty="n", inset=c(0,0.2))
#
# }
# if(family_nm=='Bunitu'){
#   plot( roc_perf, add = TRUE, col= "black", lty=5)
#   legend("topright", c(family_nm), lty=5,
#          col = "black", bty="n", inset=c(0,0.3))
#
# }
return(list(cnfMatrix$byClass['Balanced Accuracy'][1],cnfMatrix$byClass['Precision'],
cnfMatrix$byClass['Recall'],cnfMatrix$byClass['F1'],
auc_value))
}
########################## Perform Leave-One-Bot Out  ##############################
perform_LOO <- function(LOO_datasets, thresh, mtype="lr"){
if(mtype == "nn"){mtype = "mlpML" }
mal_data <- LOO_datasets[[1]]
family_mal_data <- LOO_datasets[[2]]
if(mtype == "lr"){
# Apply log trnasform to skewed predictors
mal_data[skewed_columns] <- sapply(mal_data[skewed_columns], function(x) log(x+1))
family_mal_data[skewed_columns] <- sapply(family_mal_data[skewed_columns], function(x) log(x+1))
# Create final model with LOO as test and all other as train
final_model <- cv.glmnet(as.matrix(mal_data[,-c(1)]),as.matrix(mal_data[,'Malicious']), alpha = 1)
final_lambda_lse <- final_model$lambda.1se
#Evaluate model on LOO test data
probs <- predict(final_model,newx = as.matrix(family_mal_data[,-c(1)]),s=final_lambda_lse,type="response")
preds <- rep(0,nrow(probs))
preds[probs>thresh] <- 1
}
else{ #use caret packet to train any other model type (rf, nb, svm,nn)
mlp_grid = NULL
preProc = c("center")
if(mtype == "mlpML"){ #if nn, need to set up params for tuneGrid. Otherwise, set mlp_grid to empty variable
num_vars = ncol(mal_data)-1
mlp_grid = expand.grid(layer1 = c(10),
layer2 = c(5),
layer3 = c(0))
preProc <- c("range")
}
#if(mtype == "nb"){
#    }
cluster <- makeCluster(detectCores())
registerDoParallel(cluster)
set.seed(234)
control <- trainControl(method="cv",
summaryFunction=twoClassSummary, classProbs=T,
savePredictions = T,allowParallel = TRUE)
#Convert response variable to factor for train and test datasets
mal_data$Malicious <- as.factor(mal_data$Malicious)
levels(mal_data$Malicious) <- c('Benign','Malicious')
family_mal_data$Malicious <- as.factor(family_mal_data$Malicious)
levels(family_mal_data$Malicious) <- c('Benign','Malicious')
#train model
model <- train(x=mal_data[,-1], y = as.factor(mal_data[,'Malicious']), method = mtype,
trControl=control,
preProcess = preProc,
metric = "ROC",
tuneLength = 4,
tuneGrid = mlp_grid)
#predict on test data and calculate accuracy
probs <- predict(model,newdata = family_mal_data[,-c(1)], type="prob")
probs <- probs$Malicious
preds <- rep(0,length(probs))
preds[probs>thresh] <- 1
preds <- as.factor(preds)
levels(preds) <- c('Benign', 'Malicious')
preds_table <- table(family_mal_data[,'Malicious'], preds)
accuracy <- (preds_table[1,1] + preds_table[2,2]) / sum(preds_table)
}
# Create confusion matrix
cnfMatrix <- confusionMatrix(preds, family_mal_data[,'Malicious'])
# Calculate AUC values
roccurve <- pROC::roc(family_mal_data[,'Malicious'] ~ as.vector(probs))#
#plot(roccurve)
auc_value <- pROC::auc(roccurve)
return(list(cnfMatrix$byClass['Balanced Accuracy'][1],cnfMatrix$byClass['Precision'],
cnfMatrix$byClass['Recall'],cnfMatrix$byClass['F1'],
auc_value))
}
########################## Implement Leave-One-Out ##############################
# For logistic regreeion, set custom threshold for each family
family_thresh <- c(0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5)
names(family_thresh) <- c('Miuref','Bunitu','Upatre','Dridex','Necurs','Trickbot','Conflicker','Zeus')
# Create empty dataframe loo_df
loo_df <- data.frame(family = character(), balanced_accuracy = integer(), precision = integer(), recall = integer(), F1Score = integer(), auc = integer())
# Iterate through all botnet families one by one and implement Leave-One-Out
for(family_nm in names(family_thresh)){
loo_datasets <- create_LOO_datasets(all_data = all_data,family_nm = family_nm, thresh=0.5)
#loo_outcome <- logistic_regr_LOO(loo_datasets, thresh = family_thresh[family_nm])
loo_outcome <- perform_LOO(loo_datasets, thresh = family_thresh[family_nm], mtype="nb")
loo_df <- rbind(loo_df, data.frame(family = family_nm, balanced_accuracy = unlist(loo_outcome)[[1]],
precision = unlist(loo_outcome)[[2]] , recall= unlist(loo_outcome)[[3]],
F1Score = unlist(loo_outcome)[[4]], auc = unlist(loo_outcome)[[5]]))
}
perform_LOO <- function(LOO_datasets, thresh, mtype="lr"){
if(mtype == "nn"){mtype = "mlpML" }
mal_data <- LOO_datasets[[1]]
family_mal_data <- LOO_datasets[[2]]
if(mtype == "lr"){
# Apply log trnasform to skewed predictors
mal_data[skewed_columns] <- sapply(mal_data[skewed_columns], function(x) log(x+1))
family_mal_data[skewed_columns] <- sapply(family_mal_data[skewed_columns], function(x) log(x+1))
# Create final model with LOO as test and all other as train
final_model <- cv.glmnet(as.matrix(mal_data[,-c(1)]),as.matrix(mal_data[,'Malicious']), alpha = 1)
final_lambda_lse <- final_model$lambda.1se
#Evaluate model on LOO test data
probs <- predict(final_model,newx = as.matrix(family_mal_data[,-c(1)]),s=final_lambda_lse,type="response")
preds <- rep(0,nrow(probs))
preds[probs>thresh] <- 1
}
else{ #use caret packet to train any other model type (rf, nb, svm,nn)
mlp_grid = NULL
preProc = c("center")
if(mtype == "mlpML"){ #if nn, need to set up params for tuneGrid. Otherwise, set mlp_grid to empty variable
num_vars = ncol(mal_data)-1
mlp_grid = expand.grid(layer1 = c(10),
layer2 = c(5),
layer3 = c(0))
preProc <- c("range")
}
if(mtype == "nb"){
drop_cols <- c('C', 'I', 'Q', 'T', 'c', 'i', 'q', 's', 't')
mal_data <- mal_data[,!(colnames(mal_data) %in% drop_cols)]
}
cluster <- makeCluster(detectCores())
registerDoParallel(cluster)
set.seed(234)
control <- trainControl(method="cv",
summaryFunction=twoClassSummary, classProbs=T,
savePredictions = T,allowParallel = TRUE)
#Convert response variable to factor for train and test datasets
mal_data$Malicious <- as.factor(mal_data$Malicious)
levels(mal_data$Malicious) <- c('Benign','Malicious')
family_mal_data$Malicious <- as.factor(family_mal_data$Malicious)
levels(family_mal_data$Malicious) <- c('Benign','Malicious')
#train model
model <- train(x=mal_data[,-1], y = as.factor(mal_data[,'Malicious']), method = mtype,
trControl=control,
preProcess = preProc,
metric = "ROC",
tuneLength = 4,
tuneGrid = mlp_grid)
#predict on test data and calculate accuracy
probs <- predict(model,newdata = family_mal_data[,-c(1)], type="prob")
probs <- probs$Malicious
preds <- rep(0,length(probs))
preds[probs>thresh] <- 1
preds <- as.factor(preds)
levels(preds) <- c('Benign', 'Malicious')
preds_table <- table(family_mal_data[,'Malicious'], preds)
accuracy <- (preds_table[1,1] + preds_table[2,2]) / sum(preds_table)
}
# Create confusion matrix
cnfMatrix <- confusionMatrix(preds, family_mal_data[,'Malicious'])
# Calculate AUC values
roccurve <- pROC::roc(family_mal_data[,'Malicious'] ~ as.vector(probs))#
#plot(roccurve)
auc_value <- pROC::auc(roccurve)
return(list(cnfMatrix$byClass['Balanced Accuracy'][1],cnfMatrix$byClass['Precision'],
cnfMatrix$byClass['Recall'],cnfMatrix$byClass['F1'],
auc_value))
}
family_thresh <- c(0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5)
names(family_thresh) <- c('Miuref','Bunitu','Upatre','Dridex','Necurs','Trickbot','Conflicker','Zeus')
# Create empty dataframe loo_df
loo_df <- data.frame(family = character(), balanced_accuracy = integer(), precision = integer(), recall = integer(), F1Score = integer(), auc = integer())
# Iterate through all botnet families one by one and implement Leave-One-Out
for(family_nm in names(family_thresh)){
loo_datasets <- create_LOO_datasets(all_data = all_data,family_nm = family_nm, thresh=0.5)
#loo_outcome <- logistic_regr_LOO(loo_datasets, thresh = family_thresh[family_nm])
loo_outcome <- perform_LOO(loo_datasets, thresh = family_thresh[family_nm], mtype="nb")
loo_df <- rbind(loo_df, data.frame(family = family_nm, balanced_accuracy = unlist(loo_outcome)[[1]],
precision = unlist(loo_outcome)[[2]] , recall= unlist(loo_outcome)[[3]],
F1Score = unlist(loo_outcome)[[4]], auc = unlist(loo_outcome)[[5]]))
}
warnings()
print(loo_df)
