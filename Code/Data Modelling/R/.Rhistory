accuracy <- (preds_table[1,1] + preds_table[2,2]) / sum(preds_table)
}
# Create confusion matrix
cnfMatrix <- confusionMatrix(preds, family_mal_data[,'Malicious'])
# Calculate AUC values
roccurve <- pROC::roc(family_mal_data[,'Malicious'] ~ as.vector(probs))#
#plot(roccurve)
auc_value <- pROC::auc(roccurve)
# Create ROC plots using ROCR package
roc_pred <- ROCR::prediction( as.vector(probs), family_mal_data[,'Malicious'] )
roc_perf <- ROCR::performance( roc_pred, "tpr", "fpr" )
# Create ROC plots for Miuref and Bunitu
if(family_nm=='Miuref'){
plot( roc_perf, col = "black", lty=3)
legend("topright", c(family_nm), lty=3,
col = "black", bty="n", inset=c(0,0.2))
}
if(family_nm=='Bunitu'){
par(bg = "gray90")
plot(roc_perf, add = T, col= "red", lty=5)
legend("topright", c("Logistic Regression"), lty=1,
col = "red", bty="n", inset=c(0,0.7), cex= 0.7 )
abline(a=0, b= 1)
}
return(list(cnfMatrix$byClass['Balanced Accuracy'][1],cnfMatrix$byClass['Precision'],
cnfMatrix$byClass['Recall'],cnfMatrix$byClass['F1'],
auc_value))
}
for(family_nm in names(family_thresh)){
loo_datasets <- create_LOO_datasets(all_data = all_data,family_nm = family_nm, thresh=0.5)
#loo_outcome <- logistic_regr_LOO(loo_datasets, thresh = family_thresh[family_nm])
loo_outcome <- perform_LOO(loo_datasets, thresh = family_thresh[family_nm], mtype="lr")
loo_df <- rbind(loo_df, data.frame(family = family_nm, balanced_accuracy = unlist(loo_outcome)[[1]],
precision = unlist(loo_outcome)[[2]] , recall= unlist(loo_outcome)[[3]],
F1Score = unlist(loo_outcome)[[4]], auc = unlist(loo_outcome)[[5]]))
}
perform_LOO <- function(LOO_datasets, thresh, mtype="lr"){
if(mtype == "nn"){mtype = "mlpML" }
mal_data <- LOO_datasets[[1]]
family_mal_data <- LOO_datasets[[2]]
if(mtype == "lr"){
# Apply log trnasform to skewed predictors
mal_data[skewed_columns] <- sapply(mal_data[skewed_columns], function(x) log(x+1))
family_mal_data[skewed_columns] <- sapply(family_mal_data[skewed_columns], function(x) log(x+1))
# Create final model with LOO as test and all other as train
final_model <- cv.glmnet(as.matrix(mal_data[,-c(1)]),as.matrix(mal_data[,'Malicious']), alpha = 1)
final_lambda_lse <- final_model$lambda.1se
#Evaluate model on LOO test data
probs <- predict(final_model,newx = as.matrix(family_mal_data[,-c(1)]),s=final_lambda_lse,type="response")
preds <- rep(0,nrow(probs))
preds[probs>thresh] <- 1
}
else{ #use caret packet to train any other model type (rf, nb, svm,nn)
mlp_grid = NULL
preProc = c("center")
if(mtype == "mlpML"){ #if nn, need to set up params for tuneGrid. Otherwise, set mlp_grid to empty variable
num_vars = ncol(mal_data)-1
mlp_grid = expand.grid(layer1 = c(10),
layer2 = c(5),
layer3 = c(0))
preProc <- c("range")
}
else if (mtype == "nb"){
drop_cols <- c('C', 'I', 'Q', 'T', 'c', 'i', 'q', 's', 't')
mal_data <- mal_data[,!(colnames(mal_data) %in% drop_cols)]
}
cluster <- makeCluster(detectCores())
registerDoParallel(cluster)
set.seed(234)
control <- trainControl(method="cv",
summaryFunction=twoClassSummary, classProbs=T,
savePredictions = T,allowParallel = TRUE)
#Convert response variable to factor for train and test datasets
mal_data$Malicious <- as.factor(mal_data$Malicious)
levels(mal_data$Malicious) <- c('Benign','Malicious')
family_mal_data$Malicious <- as.factor(family_mal_data$Malicious)
levels(family_mal_data$Malicious) <- c('Benign','Malicious')
#train model
model <- train(x=mal_data[,-1], y = as.factor(mal_data[,'Malicious']), method = mtype,
trControl=control,
preProcess = preProc,
metric = "ROC",
tuneLength = 4,
tuneGrid = mlp_grid)
#predict on test data and calculate accuracy
probs <- predict(model,newdata = family_mal_data[,-c(1)], type="prob")
probs <- probs$Malicious
preds <- rep(0,length(probs))
preds[probs>thresh] <- 1
preds <- as.factor(preds)
levels(preds) <- c('Benign', 'Malicious')
preds_table <- table(family_mal_data[,'Malicious'], preds)
accuracy <- (preds_table[1,1] + preds_table[2,2]) / sum(preds_table)
}
# Create confusion matrix
cnfMatrix <- confusionMatrix(preds, family_mal_data[,'Malicious'])
# Calculate AUC values
roccurve <- pROC::roc(family_mal_data[,'Malicious'] ~ as.vector(probs))#
#plot(roccurve)
auc_value <- pROC::auc(roccurve)
# Create ROC plots using ROCR package
roc_pred <- ROCR::prediction( as.vector(probs), family_mal_data[,'Malicious'] )
roc_perf <- ROCR::performance( roc_pred, "tpr", "fpr" )
# Create ROC plots for Miuref and Bunitu
if(family_nm=='Miuref'){
plot( roc_perf, col = "black", lty=3)
legend("topright", c(family_nm), lty=3,
col = "black", bty="n", inset=c(0,0.2))
}
if(family_nm=='Bunitu'){
par(bg = "gray90")
plot(roc_perf, add = F, col= "red", lty=5)
legend("topright", c("LR"), lty=1,
col = "red", bty="n", inset=c(0,0.7), cex= 0.7 )
abline(a=0, b= 1)
}
return(list(cnfMatrix$byClass['Balanced Accuracy'][1],cnfMatrix$byClass['Precision'],
cnfMatrix$byClass['Recall'],cnfMatrix$byClass['F1'],
auc_value))
}
for(family_nm in names(family_thresh)){
loo_datasets <- create_LOO_datasets(all_data = all_data,family_nm = family_nm, thresh=0.5)
#loo_outcome <- logistic_regr_LOO(loo_datasets, thresh = family_thresh[family_nm])
loo_outcome <- perform_LOO(loo_datasets, thresh = family_thresh[family_nm], mtype="lr")
loo_df <- rbind(loo_df, data.frame(family = family_nm, balanced_accuracy = unlist(loo_outcome)[[1]],
precision = unlist(loo_outcome)[[2]] , recall= unlist(loo_outcome)[[3]],
F1Score = unlist(loo_outcome)[[4]], auc = unlist(loo_outcome)[[5]]))
}
perform_LOO <- function(LOO_datasets, thresh, mtype="lr"){
if(mtype == "nn"){mtype = "mlpML" }
mal_data <- LOO_datasets[[1]]
family_mal_data <- LOO_datasets[[2]]
if(mtype == "lr"){
# Apply log trnasform to skewed predictors
mal_data[skewed_columns] <- sapply(mal_data[skewed_columns], function(x) log(x+1))
family_mal_data[skewed_columns] <- sapply(family_mal_data[skewed_columns], function(x) log(x+1))
# Create final model with LOO as test and all other as train
final_model <- cv.glmnet(as.matrix(mal_data[,-c(1)]),as.matrix(mal_data[,'Malicious']), alpha = 1)
final_lambda_lse <- final_model$lambda.1se
#Evaluate model on LOO test data
probs <- predict(final_model,newx = as.matrix(family_mal_data[,-c(1)]),s=final_lambda_lse,type="response")
preds <- rep(0,nrow(probs))
preds[probs>thresh] <- 1
}
else{ #use caret packet to train any other model type (rf, nb, svm,nn)
mlp_grid = NULL
preProc = c("center")
if(mtype == "mlpML"){ #if nn, need to set up params for tuneGrid. Otherwise, set mlp_grid to empty variable
num_vars = ncol(mal_data)-1
mlp_grid = expand.grid(layer1 = c(10),
layer2 = c(5),
layer3 = c(0))
preProc <- c("range")
}
else if (mtype == "nb"){
drop_cols <- c('C', 'I', 'Q', 'T', 'c', 'i', 'q', 's', 't')
mal_data <- mal_data[,!(colnames(mal_data) %in% drop_cols)]
}
cluster <- makeCluster(detectCores())
registerDoParallel(cluster)
set.seed(234)
control <- trainControl(method="cv",
summaryFunction=twoClassSummary, classProbs=T,
savePredictions = T,allowParallel = TRUE)
#Convert response variable to factor for train and test datasets
mal_data$Malicious <- as.factor(mal_data$Malicious)
levels(mal_data$Malicious) <- c('Benign','Malicious')
family_mal_data$Malicious <- as.factor(family_mal_data$Malicious)
levels(family_mal_data$Malicious) <- c('Benign','Malicious')
#train model
model <- train(x=mal_data[,-1], y = as.factor(mal_data[,'Malicious']), method = mtype,
trControl=control,
preProcess = preProc,
metric = "ROC",
tuneLength = 4,
tuneGrid = mlp_grid)
#predict on test data and calculate accuracy
probs <- predict(model,newdata = family_mal_data[,-c(1)], type="prob")
probs <- probs$Malicious
preds <- rep(0,length(probs))
preds[probs>thresh] <- 1
preds <- as.factor(preds)
levels(preds) <- c('Benign', 'Malicious')
preds_table <- table(family_mal_data[,'Malicious'], preds)
accuracy <- (preds_table[1,1] + preds_table[2,2]) / sum(preds_table)
}
# Create confusion matrix
cnfMatrix <- confusionMatrix(preds, family_mal_data[,'Malicious'])
# Calculate AUC values
roccurve <- pROC::roc(family_mal_data[,'Malicious'] ~ as.vector(probs))#
#plot(roccurve)
auc_value <- pROC::auc(roccurve)
# Create ROC plots using ROCR package
roc_pred <- ROCR::prediction( as.vector(probs), family_mal_data[,'Malicious'] )
roc_perf <- ROCR::performance( roc_pred, "tpr", "fpr" )
# Create ROC plots for Miuref and Bunitu
if(family_nm=='Miuref'){
plot( roc_perf, col = "black", lty=3)
legend("topright", c(family_nm), lty=3,
col = "black", bty="n", inset=c(0,0.2))
}
if(family_nm=='Bunitu'){
par(bg = "gray90")
plot(roc_perf, add = T, col= "brown", lty=5)
legend("topright", c("NB"), lty=1,
col = "brown", bty="n", inset=c(0,0.9), cex= 0.7 )
abline(a=0, b= 1)
}
return(list(cnfMatrix$byClass['Balanced Accuracy'][1],cnfMatrix$byClass['Precision'],
cnfMatrix$byClass['Recall'],cnfMatrix$byClass['F1'],
auc_value))
}
for(family_nm in names(family_thresh)){
loo_datasets <- create_LOO_datasets(all_data = all_data,family_nm = family_nm, thresh=0.5)
#loo_outcome <- logistic_regr_LOO(loo_datasets, thresh = family_thresh[family_nm])
loo_outcome <- perform_LOO(loo_datasets, thresh = family_thresh[family_nm], mtype="NB")
loo_df <- rbind(loo_df, data.frame(family = family_nm, balanced_accuracy = unlist(loo_outcome)[[1]],
precision = unlist(loo_outcome)[[2]] , recall= unlist(loo_outcome)[[3]],
F1Score = unlist(loo_outcome)[[4]], auc = unlist(loo_outcome)[[5]]))
}
for(family_nm in names(family_thresh)){
loo_datasets <- create_LOO_datasets(all_data = all_data,family_nm = family_nm, thresh=0.5)
#loo_outcome <- logistic_regr_LOO(loo_datasets, thresh = family_thresh[family_nm])
loo_outcome <- perform_LOO(loo_datasets, thresh = family_thresh[family_nm], mtype="nb")
loo_df <- rbind(loo_df, data.frame(family = family_nm, balanced_accuracy = unlist(loo_outcome)[[1]],
precision = unlist(loo_outcome)[[2]] , recall= unlist(loo_outcome)[[3]],
F1Score = unlist(loo_outcome)[[4]], auc = unlist(loo_outcome)[[5]]))
}
perform_LOO <- function(LOO_datasets, thresh, mtype="lr"){
if(mtype == "nn"){mtype = "mlpML" }
mal_data <- LOO_datasets[[1]]
family_mal_data <- LOO_datasets[[2]]
if(mtype == "lr"){
# Apply log trnasform to skewed predictors
mal_data[skewed_columns] <- sapply(mal_data[skewed_columns], function(x) log(x+1))
family_mal_data[skewed_columns] <- sapply(family_mal_data[skewed_columns], function(x) log(x+1))
# Create final model with LOO as test and all other as train
final_model <- cv.glmnet(as.matrix(mal_data[,-c(1)]),as.matrix(mal_data[,'Malicious']), alpha = 1)
final_lambda_lse <- final_model$lambda.1se
#Evaluate model on LOO test data
probs <- predict(final_model,newx = as.matrix(family_mal_data[,-c(1)]),s=final_lambda_lse,type="response")
preds <- rep(0,nrow(probs))
preds[probs>thresh] <- 1
}
else{ #use caret packet to train any other model type (rf, nb, svm,nn)
mlp_grid = NULL
preProc = c("center")
if(mtype == "mlpML"){ #if nn, need to set up params for tuneGrid. Otherwise, set mlp_grid to empty variable
num_vars = ncol(mal_data)-1
mlp_grid = expand.grid(layer1 = c(10),
layer2 = c(5),
layer3 = c(0))
preProc <- c("range")
}
else if (mtype == "nb"){
drop_cols <- c('C', 'I', 'Q', 'T', 'c', 'i', 'q', 's', 't')
mal_data <- mal_data[,!(colnames(mal_data) %in% drop_cols)]
}
cluster <- makeCluster(detectCores())
registerDoParallel(cluster)
set.seed(234)
control <- trainControl(method="cv",
summaryFunction=twoClassSummary, classProbs=T,
savePredictions = T,allowParallel = TRUE)
#Convert response variable to factor for train and test datasets
mal_data$Malicious <- as.factor(mal_data$Malicious)
levels(mal_data$Malicious) <- c('Benign','Malicious')
family_mal_data$Malicious <- as.factor(family_mal_data$Malicious)
levels(family_mal_data$Malicious) <- c('Benign','Malicious')
#train model
model <- train(x=mal_data[,-1], y = as.factor(mal_data[,'Malicious']), method = mtype,
trControl=control,
preProcess = preProc,
metric = "ROC",
tuneLength = 4,
tuneGrid = mlp_grid)
#predict on test data and calculate accuracy
probs <- predict(model,newdata = family_mal_data[,-c(1)], type="prob")
probs <- probs$Malicious
preds <- rep(0,length(probs))
preds[probs>thresh] <- 1
preds <- as.factor(preds)
levels(preds) <- c('Benign', 'Malicious')
preds_table <- table(family_mal_data[,'Malicious'], preds)
accuracy <- (preds_table[1,1] + preds_table[2,2]) / sum(preds_table)
}
# Create confusion matrix
cnfMatrix <- confusionMatrix(preds, family_mal_data[,'Malicious'])
# Calculate AUC values
roccurve <- pROC::roc(family_mal_data[,'Malicious'] ~ as.vector(probs))#
#plot(roccurve)
auc_value <- pROC::auc(roccurve)
# Create ROC plots using ROCR package
roc_pred <- ROCR::prediction( as.vector(probs), family_mal_data[,'Malicious'] )
roc_perf <- ROCR::performance( roc_pred, "tpr", "fpr" )
# Create ROC plots for Miuref and Bunitu
if(family_nm=='Miuref'){
plot( roc_perf, col = "black", lty=3)
legend("topright", c(family_nm), lty=3,
col = "black", bty="n", inset=c(0,0.2))
}
if(family_nm=='Bunitu'){
par(bg = "gray90")
plot(roc_perf, add = T, col= "pink", lty=5)
legend("topright", c("RF"), lty=1,
col = "pink", bty="n", inset=c(0,0.8), cex= 0.7 )
abline(a=0, b= 1)
}
return(list(cnfMatrix$byClass['Balanced Accuracy'][1],cnfMatrix$byClass['Precision'],
cnfMatrix$byClass['Recall'],cnfMatrix$byClass['F1'],
auc_value))
}
for(family_nm in names(family_thresh)){
loo_datasets <- create_LOO_datasets(all_data = all_data,family_nm = family_nm, thresh=0.5)
#loo_outcome <- logistic_regr_LOO(loo_datasets, thresh = family_thresh[family_nm])
loo_outcome <- perform_LOO(loo_datasets, thresh = family_thresh[family_nm], mtype="nb")
loo_df <- rbind(loo_df, data.frame(family = family_nm, balanced_accuracy = unlist(loo_outcome)[[1]],
precision = unlist(loo_outcome)[[2]] , recall= unlist(loo_outcome)[[3]],
F1Score = unlist(loo_outcome)[[4]], auc = unlist(loo_outcome)[[5]]))
}
for(family_nm in names(family_thresh)){
loo_datasets <- create_LOO_datasets(all_data = all_data,family_nm = family_nm, thresh=0.5)
#loo_outcome <- logistic_regr_LOO(loo_datasets, thresh = family_thresh[family_nm])
loo_outcome <- perform_LOO(loo_datasets, thresh = family_thresh[family_nm], mtype="rf")
loo_df <- rbind(loo_df, data.frame(family = family_nm, balanced_accuracy = unlist(loo_outcome)[[1]],
precision = unlist(loo_outcome)[[2]] , recall= unlist(loo_outcome)[[3]],
F1Score = unlist(loo_outcome)[[4]], auc = unlist(loo_outcome)[[5]]))
}
perform_LOO <- function(LOO_datasets, thresh, mtype="lr"){
if(mtype == "nn"){mtype = "mlpML" }
mal_data <- LOO_datasets[[1]]
family_mal_data <- LOO_datasets[[2]]
if(mtype == "lr"){
# Apply log trnasform to skewed predictors
mal_data[skewed_columns] <- sapply(mal_data[skewed_columns], function(x) log(x+1))
family_mal_data[skewed_columns] <- sapply(family_mal_data[skewed_columns], function(x) log(x+1))
# Create final model with LOO as test and all other as train
final_model <- cv.glmnet(as.matrix(mal_data[,-c(1)]),as.matrix(mal_data[,'Malicious']), alpha = 1)
final_lambda_lse <- final_model$lambda.1se
#Evaluate model on LOO test data
probs <- predict(final_model,newx = as.matrix(family_mal_data[,-c(1)]),s=final_lambda_lse,type="response")
preds <- rep(0,nrow(probs))
preds[probs>thresh] <- 1
}
else{ #use caret packet to train any other model type (rf, nb, svm,nn)
mlp_grid = NULL
preProc = c("center")
if(mtype == "mlpML"){ #if nn, need to set up params for tuneGrid. Otherwise, set mlp_grid to empty variable
num_vars = ncol(mal_data)-1
mlp_grid = expand.grid(layer1 = c(10),
layer2 = c(5),
layer3 = c(0))
preProc <- c("range")
}
else if (mtype == "nb"){
drop_cols <- c('C', 'I', 'Q', 'T', 'c', 'i', 'q', 's', 't')
mal_data <- mal_data[,!(colnames(mal_data) %in% drop_cols)]
}
cluster <- makeCluster(detectCores())
registerDoParallel(cluster)
set.seed(234)
control <- trainControl(method="cv",
summaryFunction=twoClassSummary, classProbs=T,
savePredictions = T,allowParallel = TRUE)
#Convert response variable to factor for train and test datasets
mal_data$Malicious <- as.factor(mal_data$Malicious)
levels(mal_data$Malicious) <- c('Benign','Malicious')
family_mal_data$Malicious <- as.factor(family_mal_data$Malicious)
levels(family_mal_data$Malicious) <- c('Benign','Malicious')
#train model
model <- train(x=mal_data[,-1], y = as.factor(mal_data[,'Malicious']), method = mtype,
trControl=control,
preProcess = preProc,
metric = "ROC",
tuneLength = 4,
tuneGrid = mlp_grid)
#predict on test data and calculate accuracy
probs <- predict(model,newdata = family_mal_data[,-c(1)], type="prob")
probs <- probs$Malicious
preds <- rep(0,length(probs))
preds[probs>thresh] <- 1
preds <- as.factor(preds)
levels(preds) <- c('Benign', 'Malicious')
preds_table <- table(family_mal_data[,'Malicious'], preds)
accuracy <- (preds_table[1,1] + preds_table[2,2]) / sum(preds_table)
}
# Create confusion matrix
cnfMatrix <- confusionMatrix(preds, family_mal_data[,'Malicious'])
# Calculate AUC values
roccurve <- pROC::roc(family_mal_data[,'Malicious'] ~ as.vector(probs))#
#plot(roccurve)
auc_value <- pROC::auc(roccurve)
# Create ROC plots using ROCR package
roc_pred <- ROCR::prediction( as.vector(probs), family_mal_data[,'Malicious'] )
roc_perf <- ROCR::performance( roc_pred, "tpr", "fpr" )
# Create ROC plots for Miuref and Bunitu
if(family_nm=='Miuref'){
plot( roc_perf, col = "black", lty=3)
legend("topright", c(family_nm), lty=3,
col = "black", bty="n", inset=c(0,0.2))
}
if(family_nm=='Bunitu'){
par(bg = "gray90")
plot(roc_perf, add = T, col= "green", lty=5)
legend("topright", c("NN"), lty=1,
col = "green", bty="n", inset=c(0,0.6), cex= 0.7 )
abline(a=0, b= 1)
}
return(list(cnfMatrix$byClass['Balanced Accuracy'][1],cnfMatrix$byClass['Precision'],
cnfMatrix$byClass['Recall'],cnfMatrix$byClass['F1'],
auc_value))
}
for(family_nm in names(family_thresh)){
loo_datasets <- create_LOO_datasets(all_data = all_data,family_nm = family_nm, thresh=0.5)
#loo_outcome <- logistic_regr_LOO(loo_datasets, thresh = family_thresh[family_nm])
loo_outcome <- perform_LOO(loo_datasets, thresh = family_thresh[family_nm], mtype="mlpML")
loo_df <- rbind(loo_df, data.frame(family = family_nm, balanced_accuracy = unlist(loo_outcome)[[1]],
precision = unlist(loo_outcome)[[2]] , recall= unlist(loo_outcome)[[3]],
F1Score = unlist(loo_outcome)[[4]], auc = unlist(loo_outcome)[[5]]))
}
perform_LOO <- function(LOO_datasets, thresh, mtype="lr"){
if(mtype == "nn"){mtype = "mlpML" }
mal_data <- LOO_datasets[[1]]
family_mal_data <- LOO_datasets[[2]]
if(mtype == "lr"){
# Apply log trnasform to skewed predictors
mal_data[skewed_columns] <- sapply(mal_data[skewed_columns], function(x) log(x+1))
family_mal_data[skewed_columns] <- sapply(family_mal_data[skewed_columns], function(x) log(x+1))
# Create final model with LOO as test and all other as train
final_model <- cv.glmnet(as.matrix(mal_data[,-c(1)]),as.matrix(mal_data[,'Malicious']), alpha = 1)
final_lambda_lse <- final_model$lambda.1se
#Evaluate model on LOO test data
probs <- predict(final_model,newx = as.matrix(family_mal_data[,-c(1)]),s=final_lambda_lse,type="response")
preds <- rep(0,nrow(probs))
preds[probs>thresh] <- 1
}
else{ #use caret packet to train any other model type (rf, nb, svm,nn)
mlp_grid = NULL
preProc = c("center")
if(mtype == "mlpML"){ #if nn, need to set up params for tuneGrid. Otherwise, set mlp_grid to empty variable
num_vars = ncol(mal_data)-1
mlp_grid = expand.grid(layer1 = c(10),
layer2 = c(5),
layer3 = c(0))
preProc <- c("range")
}
else if (mtype == "nb"){
drop_cols <- c('C', 'I', 'Q', 'T', 'c', 'i', 'q', 's', 't')
mal_data <- mal_data[,!(colnames(mal_data) %in% drop_cols)]
}
cluster <- makeCluster(detectCores())
registerDoParallel(cluster)
set.seed(234)
control <- trainControl(method="cv",
summaryFunction=twoClassSummary, classProbs=T,
savePredictions = T,allowParallel = TRUE)
#Convert response variable to factor for train and test datasets
mal_data$Malicious <- as.factor(mal_data$Malicious)
levels(mal_data$Malicious) <- c('Benign','Malicious')
family_mal_data$Malicious <- as.factor(family_mal_data$Malicious)
levels(family_mal_data$Malicious) <- c('Benign','Malicious')
#train model
model <- train(x=mal_data[,-1], y = as.factor(mal_data[,'Malicious']), method = mtype,
trControl=control,
preProcess = preProc,
metric = "ROC",
tuneLength = 4,
tuneGrid = mlp_grid)
#predict on test data and calculate accuracy
probs <- predict(model,newdata = family_mal_data[,-c(1)], type="prob")
probs <- probs$Malicious
preds <- rep(0,length(probs))
preds[probs>thresh] <- 1
preds <- as.factor(preds)
levels(preds) <- c('Benign', 'Malicious')
preds_table <- table(family_mal_data[,'Malicious'], preds)
accuracy <- (preds_table[1,1] + preds_table[2,2]) / sum(preds_table)
}
# Create confusion matrix
cnfMatrix <- confusionMatrix(preds, family_mal_data[,'Malicious'])
# Calculate AUC values
roccurve <- pROC::roc(family_mal_data[,'Malicious'] ~ as.vector(probs))#
#plot(roccurve)
auc_value <- pROC::auc(roccurve)
# Create ROC plots using ROCR package
roc_pred <- ROCR::prediction( as.vector(probs), family_mal_data[,'Malicious'] )
roc_perf <- ROCR::performance( roc_pred, "tpr", "fpr" )
# Create ROC plots for Miuref and Bunitu
if(family_nm=='Miuref'){
plot( roc_perf, col = "black", lty=3)
legend("topright", c(family_nm), lty=3,
col = "black", bty="n", inset=c(0,0.2))
}
if(family_nm=='Bunitu'){
par(bg = "gray90")
plot(roc_perf, add = T, col= "blue", lty=5)
legend("topright", c("SVM"), lty=1,
col = "blue", bty="n", inset=c(0,0.5), cex= 0.7 )
abline(a=0, b= 1)
}
return(list(cnfMatrix$byClass['Balanced Accuracy'][1],cnfMatrix$byClass['Precision'],
cnfMatrix$byClass['Recall'],cnfMatrix$byClass['F1'],
auc_value))
}
for(family_nm in names(family_thresh)){
loo_datasets <- create_LOO_datasets(all_data = all_data,family_nm = family_nm, thresh=0.5)
#loo_outcome <- logistic_regr_LOO(loo_datasets, thresh = family_thresh[family_nm])
loo_outcome <- perform_LOO(loo_datasets, thresh = family_thresh[family_nm], mtype="svmRadial")
loo_df <- rbind(loo_df, data.frame(family = family_nm, balanced_accuracy = unlist(loo_outcome)[[1]],
precision = unlist(loo_outcome)[[2]] , recall= unlist(loo_outcome)[[3]],
F1Score = unlist(loo_outcome)[[4]], auc = unlist(loo_outcome)[[5]]))
}
